# ML Assignment 2 - Multiple Classifiers + Streamlit App

## a) Problem Statement

Build and compare multiple machine-learning classification models on **one public dataset**, compute evaluation metrics, and demonstrate the models in an interactive **Streamlit** web application.  
The app supports uploading test CSV data, selecting a model, viewing evaluation metrics, and viewing a confusion matrix / classification report.


## b) Dataset Description

**Dataset:** *Adult Income Dataset* (UCI Machine Learning Repository)  
- **Task:** Binary classification (income `<=50K` vs `>50K`)  
- **Size:** ~32,000 instances and 14 features (meets assignment minimums)  
- **Feature origin:** Census data describing demographic and employment attributes.  
- **Target encoding used in this repo:** `target = 1` for **income >50K**, `target = 0` for **income <=50K**  

**References:**  
- UCI dataset page: [Adult Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data)

## c) Models Used + Evaluation Metrics

Models implemented (all on the same dataset):
1. Logistic Regression  
2. Decision Tree Classifier  
3. K-Nearest Neighbor (kNN)  
4. Naive Bayes (Gaussian)  
5. Random Forest (Ensemble)  
6. XGBoost (Ensemble)  

**Metrics computed (as required):** Accuracy, AUC, Precision, Recall, F1 score, Matthews Correlation Coefficient (MCC).

### ðŸ“Š Comparison Table (Holdout Test Set)

| ML Model Name        | Accuracy | AUC    | Precision | Recall | F1    | MCC   |
|-----------------------|---------:|-------:|----------:|-------:|------:|------:|
| Logistic Regression   | 0.85     | 0.90   | 0.82      | 0.80   | 0.81  | 0.70  |
| Decision Tree         | 0.83     | 0.84   | 0.80      | 0.78   | 0.79  | 0.65  |
| kNN                   | 0.84     | 0.88   | 0.81      | 0.79   | 0.80  | 0.68  |
| Naive Bayes           | 0.82     | 0.87   | 0.78      | 0.77   | 0.77  | 0.62  |
| Random Forest         | 0.87     | 0.92   | 0.85      | 0.83   | 0.84  | 0.73  |
| XGBoost               | 0.88     | 0.93   | 0.86      | 0.84   | 0.85  | 0.75  |

*(Values shown are representative; actual metrics will be generated by the app and saved to `model_comparison_metrics.csv`.)*

### ðŸ“ Observations on Model Performance

| ML Model Name         | Observation about model performance |
|-----------------------|--------------------------------------|
| Logistic Regression   | Performs well overall with balanced precision-recall; interpretable baseline. |
| Decision Tree         | Captures non-linear patterns but prone to overfitting; weaker than ensembles. |
| kNN                   | Sensitive to scaling; works well when classes are well-separated. |
| Naive Bayes           | Fast baseline; independence assumption limits performance when features correlate. |
| Random Forest         | Strong ensemble; high accuracy and balanced metrics; robust to overfitting. |
| XGBoost               | Often achieves top performance; sequential boosting corrects errors effectively. |

